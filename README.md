# Jailbreaking Deep Models: Adversarial Attack

This repository contains the code and accompanying materials for **Project 3** of the NYU Tandon ECE Deep Learning course. The goal of the project is to explore adversarial attacks on deep neural networks and evaluate their effectiveness.

## Contents

- `DL_Project3.ipynb` – Jupyter notebook with code for setting up models and performing various adversarial attacks.
- `DL_Project_3_Report.pdf` – Final project report summarizing the methodology and results.
- `labels_list.json` and `imagenet_class_index.json` – Auxiliary label information used in the notebook.

## Getting Started

To experiment with the notebook yourself, install Python 3 with PyTorch and run the notebook in Jupyter:

```bash
pip install torch torchvision notebook
jupyter notebook DL_Project3.ipynb
```

The notebook is organized by tasks, showing baseline evaluation and a sequence of increasingly sophisticated attacks. The report provides further explanations and analysis.

## License

This repository is provided for educational purposes as part of a university assignment.
